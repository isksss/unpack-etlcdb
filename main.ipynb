{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvv5P8Z4_av3"
      },
      "source": [
        "## 事前準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GoVEPJ1_glX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbe4b4f-6f7f-4daf-98be-0746261cb257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        " # google driveへの接続\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSNCxGCy_Lpg"
      },
      "source": [
        "## CONST\n",
        "定数の宣言  \n",
        "ここは各自の環境に合わせて変更してください。ここではGoogleDriveを用いて行うことにします。  \n",
        "ルートフォルダ内にdataフォルダを作成し、そこにダウンロードしたzipファイルを入れていください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gdfB8Pl6-R8_"
      },
      "outputs": [],
      "source": [
        "## rootフォルダ\n",
        "ROOT_DIR = \"/content/drive/MyDrive/Colab Notebooks/unpack-etlcdb\"\n",
        "\n",
        "## 出力フォルダ\n",
        "OUTPUT_DIR = ROOT_DIR+ \"/output\"\n",
        "\n",
        "## DATA\n",
        "DATE_DIR = \"/data\"\n",
        "\n",
        "etl9b_path = '/content/drive/MyDrive/code/ETLCDB/ETL9B.zip' # ここにetl9bのパスを入力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFndWVMjMags"
      },
      "outputs": [],
      "source": [
        "### フォルダ作成\n",
        "import os\n",
        "#### 上記のフォルダがなかった場合、作成する処理をここに入れる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPLPreeT_Twm"
      },
      "source": [
        "## 処理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il5vNCtKK-s8"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WlEY0-4H_Y8e"
      },
      "outputs": [],
      "source": [
        "### import\n",
        "import shutil\n",
        "\n",
        "import struct\n",
        "from PIL import Image, ImageEnhance\n",
        "\n",
        "import glob\n",
        "import os\n",
        "\n",
        "### make pickle\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdMbiInELAw8"
      },
      "source": [
        "### unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbCmp3AZNAaj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "shutil.unpack_archive(etl9b_path ,OUTPUT_DIR+\"/unzip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv5KV6JkLMst"
      },
      "source": [
        "### binary -> png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHDmBektNA1L"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_dir = OUTPUT_DIR + '/unzip'\n",
        "\n",
        "files = glob.glob(dataset_dir + '/ETL9B/*') # 解凍したバイナリファイルのpath\n",
        "\n",
        "err_cnt = 0\n",
        "for fname in files:\n",
        "    print('===== ===== =====')\n",
        "    if fname == dataset_dir + \"/ETL9B/ETL9BINFO\": continue # 情報ファイルは飛ばす\n",
        "    if fname == dataset_dir + \"/ETL9B/output\": continue\n",
        "\n",
        "    ### まとめて解凍すると、時間かかるから分割する。\n",
        "    # if fname == dataset_dir + \"/ETL9B/ETL9B_1\": continue \n",
        "    # if fname == dataset_dir + \"/ETL9B/ETL9B_2\": continue \n",
        "    if fname == dataset_dir + \"/ETL9B/ETL9B_3\": continue \n",
        "    if fname == dataset_dir + \"/ETL9B/ETL9B_4\": continue \n",
        "    if fname == dataset_dir + \"/ETL9B/ETL9B_5\": continue \n",
        "\n",
        "    print(fname)\n",
        "\n",
        "    f = open(fname, 'rb')\n",
        "    # f.seek(0) # ポインタを先頭に\n",
        "    f.seek(576)\n",
        "    cnt = 0\n",
        "    while True:\n",
        "        cnt += 1\n",
        "        print('----- -----　-----')\n",
        "        print(fname +\":::\" +str(cnt))\n",
        "        s = f.read(576) \n",
        "        if not s: break\n",
        "        # バイナリデータなのでPythonが理解できるように抽出\n",
        "        try:\n",
        "          r = struct.unpack('>2H4s504s64x', s)\n",
        "        except:\n",
        "          err_cnt += 1\n",
        "          continue\n",
        "        kanjicode_jis = r[1]\n",
        "\n",
        "        # 画像を抽出\n",
        "        iF = Image.frombytes('1', (64, 63), r[3], 'raw')\n",
        "        iP = iF.convert('L')\n",
        "        dir = OUTPUT_DIR+ \"/etl9b/{:x}\".format(kanjicode_jis)\n",
        "        print(dir)\n",
        "        if not os.path.exists(dir): \n",
        "          os.makedirs(dir)\n",
        "\n",
        "        #####\n",
        "        print(\"r[0]: \" + str(r[0]))\n",
        "        print(\"r[1]: \" + str(r[1]))\n",
        "        print(\"r[2]: \" + str(r[2]))\n",
        "        #####\n",
        "        fn = \"{0:02x}-{1:02x}{2}.png\".format(kanjicode_jis, r[0], r[2])\n",
        "        print('fn: ' + fn)\n",
        "        #####\n",
        "\n",
        "        fullpath = dir + \"/\" + fn\n",
        "        if os.path.exists(fullpath): continue\n",
        "        enhancer = ImageEnhance.Brightness(iP)\n",
        "        iE = enhancer.enhance(16)\n",
        "        iE.save(fullpath, 'PNG')\n",
        "\n",
        "print(\"CNT: \"+ str(cnt))\n",
        "print(\"ERR: \"+ str(err_cnt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqQzxywdLSZc"
      },
      "source": [
        "### make-pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-2Mc-jzNBXr"
      },
      "outputs": [],
      "source": [
        "# インライン表示\n",
        "%matplotlib inline\n",
        "\n",
        "# 保存ディレクトリと画像サイズの指定\n",
        "out_dir = OUTPUT_DIR + '/etl9b'\n",
        "im_size = 64 # 画像サイズ\n",
        "\n",
        "# 保存ファイル名と保存先\n",
        "save_file = OUTPUT_DIR + \"/pickle/ETL9B.dill\" \n",
        "# save_file = OUTPUT_DIR + \"/pickle/ETL9B.pickle\" \n",
        "\n",
        "# 画像ディレクトリから画像を読み込み開始\n",
        "files = os.listdir(out_dir)\n",
        "files_dir = [f for f in files if os.path.isdir(os.path.join(out_dir, f))]\n",
        "\n",
        "result = []\n",
        "\n",
        "print(files_dir)\n",
        "for i, code in enumerate(files_dir):\n",
        "    img_dir = out_dir + \"/\" + str(code)\n",
        "    fs = glob.glob(img_dir + \"/*\")\n",
        "    print(\"dir=\",  img_dir)\n",
        "\n",
        "    # test\n",
        "    print(\"CODE: \" + code)\n",
        "    print(len(result))\n",
        "\n",
        "    # 画像64X63を読み込んでグレイスケールに変換し64X64に整形\n",
        "    for j, f in enumerate(fs):\n",
        "      try:\n",
        "        img = cv2.imread(f)\n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img_gray, (im_size, im_size))\n",
        "        result.append([i, img])\n",
        "\n",
        "        ### show image\n",
        "        # print(code + \": \"+ str(j))\n",
        "        # plt.imshow(img)\n",
        "        # plt.show()\n",
        "\n",
        "      except :\n",
        "        print(\"ERROR: \"+ str(j))\n",
        "\n",
        "\n",
        "# 「画像とラベル」のデータセットを保存\n",
        "pickle.dump(result, open(save_file, \"wb\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pickleが使用できないとき\n",
        "!pip install dill\n",
        "import dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XOSc1NbD4PN",
        "outputId": "b147f222-9a9f-4ae6-ccda-f4c3c59fc8b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (0.3.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存\n",
        "\n",
        "dill_file = OUTPUT_DIR + \"/pickle/ETL9B.dill\" \n",
        "pickle_file = OUTPUT_DIR + \"/pickle/ETL9B.pickle\" \n",
        "\n",
        "try:\n",
        "  with open(pickle_file, \"wb\") as save:\n",
        "    pickle.dump(result, save)\n",
        "except:\n",
        "  with open(dill_file, \"wb\") as save:\n",
        "    dill.dump(result, save)"
      ],
      "metadata": {
        "id": "sL0Wl6-DBBKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqwSJKECQV6M"
      },
      "source": [
        "#### make pickle(sub)\n",
        "同時にdampするversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_eIK9AnQeme"
      },
      "outputs": [],
      "source": [
        "# 保存ディレクトリと画像サイズの指定\n",
        "out_dir = OUTPUT_DIR + '/etl9b'\n",
        "im_size = 64 # 画像サイズ\n",
        "\n",
        "save_file = OUTPUT_DIR + \"/pickle/ETL9B.pickle\" # 保存ファイル名と保存先\n",
        "plt.figure(figsize=(9, 17)) \n",
        "\n",
        "# 画像ディレクトリから画像を読み込み開始\n",
        "files = os.listdir(out_dir)\n",
        "files_dir = [f for f in files if os.path.isdir(os.path.join(out_dir, f))]\n",
        "\n",
        "result = []\n",
        "for i, code in enumerate(files_dir):\n",
        "    img_dir = out_dir + \"/\" + str(code)\n",
        "    fs = glob.glob(img_dir + \"/*\")\n",
        "    print(\"dir=\",  img_dir)\n",
        "\n",
        "    # 画像64X63を読み込んでグレイスケールに変換し64X64に整形\n",
        "    for j, f in enumerate(fs):\n",
        "      try:\n",
        "        img = cv2.imread(f)\n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = cv2.resize(img_gray, (im_size, im_size))\n",
        "        result.append([i, img])\n",
        "        try:\n",
        "          pickle.dump(result, open(save_file, \"ab\"))\n",
        "        except:\n",
        "          print(\"damp error:\" + str(i))\n",
        "      except :\n",
        "        print(\"ERROR: \"+ str(i))\n",
        "\n",
        "\n",
        "# 「画像とラベル」のデータセットを保存\n",
        "pickle.dump(result, open(save_file, \"ab\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlBzoYAqLW-0"
      },
      "source": [
        "### learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wVOjaYQTNB3U"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "import cv2, pickle, dill\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import utils as np_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データファイルと画像サイズの指定\n",
        "\n",
        "data_file = OUTPUT_DIR  + \"/pickle/ETL9B.pickle\" \n",
        "im_size = 64\n",
        "out_size = 3036 # 文字の数\n",
        "im_color = 1\n",
        "in_shape = (im_size, im_size, im_color)"
      ],
      "metadata": {
        "id": "MFYzYjhf0h-8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存した画像データ一覧を読み込む\n",
        "data = pickle.load(open(data_file, \"rb\"))\n"
      ],
      "metadata": {
        "id": "fxNvaho1uloQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dillファイルをお見込む場合\n",
        "dill_file = OUTPUT_DIR + \"/pickle/ETL9B.dill\" \n",
        "data = dill.load(open(dill_file, \"rb\"))\n",
        "print(len(data))"
      ],
      "metadata": {
        "id": "w1pAW6fO0RLs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###test\n",
        "for d in data:\n",
        "  (num, img) = d\n",
        "  print(num)\n",
        "  if num == 0: continue\n",
        "  img = cv2.imread(img)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "CijBG0LF9S4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像データを0-1の範囲に直す\n",
        "y = []\n",
        "x = []\n",
        "for d in data:\n",
        "  (num, img) = d\n",
        "  print(num)\n",
        "  img = img.astype('float').reshape(im_size, im_size, im_color) / 255\n",
        "  y.append(np_utils.to_categorical(num, out_size))\n",
        "  x.append(img)\n",
        "x = np.array(x)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "AWGZBAHNpJNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, shuffle=True)"
      ],
      "metadata": {
        "id": "eA8YXunMvM6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル構築\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=in_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(out_size))\n",
        "model.add(Activation('softmax'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "OCD72BN2uzCM",
        "outputId": "21fa087e-efbd-4d43-fdc6-fbeb9a65ac9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-79d2e11c048a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#モデル構築\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#コンパイル\n",
        "model.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer= 'adam',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(\n",
        "  x_train, y_train,\n",
        "  batch_size=2048, epochs=20000,verbose=1,\n",
        "    validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "OMrOvY8eu2nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(\"正解率 \", score[1], \"loss \", score[0])\n",
        "\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.title('Accuracy')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.title('Loss')\n",
        "plt.legend(['train', 'test'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "model.save('ETL9-model.h5')\n",
        "model.save_weights('ETL9-weights.h5')"
      ],
      "metadata": {
        "id": "_q_RH9uJu4ZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "main.ipynb",
      "provenance": [],
      "mount_file_id": "116_ozOm8x5VLVEGy0U7u7lxNsvTJkQ62",
      "authorship_tag": "ABX9TyMe4YaGvj7fMik/RXillXY2"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}